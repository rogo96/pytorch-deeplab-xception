{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1O8We25irSulraw8nyEJxwgqCMRY7chQb",
      "authorship_tag": "ABX9TyNCBbpc1sh2FHXNe/Wiy3cv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogo96/pytorch-deeplab-xception/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7v2VhZcSjBP",
        "outputId": "6f96759c-208a-4c04-96a0-259fe6247774"
      },
      "source": [
        "!git clone https://github.com/rogo96/pytorch-deeplab-xception.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-deeplab-xception'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 345 (delta 0), reused 0 (delta 0), pack-reused 342\u001b[K\n",
            "Receiving objects: 100% (345/345), 944.40 KiB | 5.19 MiB/s, done.\n",
            "Resolving deltas: 100% (191/191), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDky1BI5SlPh",
        "outputId": "c8d10eb2-bee7-49d3-aad2-7f5de619c39e"
      },
      "source": [
        "%cd pytorch-deeplab-xception"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-deeplab-xception\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxXs0gPNSuXl",
        "outputId": "b8202ff1-a2d2-4fc5-c05c-7d4bf77f9b1f"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPB10WZsSw78"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-VlFzNCSyaF",
        "outputId": "9d11886f-2301-45a3-cc65-19d990be9716"
      },
      "source": [
        "!pip install matplotlib pillow tensorboardX tqdm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5az2ncFSz8h",
        "outputId": "5f39295c-0a0e-45c6-c50f-b65f01208b9a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataloaders  LICENSE   mypath.py  train_coco.sh  train_voc.sh\n",
            "doc\t     modeling  README.md  train.py\t utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfaWgyUTS44J",
        "outputId": "caca7b4a-6691-4cb7-fa8b-d35cb5d0f491"
      },
      "source": [
        "!python train.py -h"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--backbone {resnet,xception,drn,mobilenet}]\n",
            "                [--out-stride OUT_STRIDE] [--dataset {pascal,coco,cityscapes}]\n",
            "                [--use-sbd] [--workers N] [--base-size BASE_SIZE]\n",
            "                [--crop-size CROP_SIZE] [--sync-bn SYNC_BN]\n",
            "                [--freeze-bn FREEZE_BN] [--loss-type {ce,focal}] [--epochs N]\n",
            "                [--start_epoch N] [--batch-size N] [--test-batch-size N]\n",
            "                [--use-balanced-weights] [--lr LR]\n",
            "                [--lr-scheduler {poly,step,cos}] [--momentum M]\n",
            "                [--weight-decay M] [--nesterov] [--no-cuda]\n",
            "                [--gpu-ids GPU_IDS] [--seed S] [--resume RESUME]\n",
            "                [--checkname CHECKNAME] [--ft] [--eval-interval EVAL_INTERVAL]\n",
            "                [--no-val]\n",
            "\n",
            "PyTorch DeeplabV3Plus Training\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --backbone {resnet,xception,drn,mobilenet}\n",
            "                        backbone name (default: resnet)\n",
            "  --out-stride OUT_STRIDE\n",
            "                        network output stride (default: 8)\n",
            "  --dataset {pascal,coco,cityscapes}\n",
            "                        dataset name (default: pascal)\n",
            "  --use-sbd             whether to use SBD dataset (default: True)\n",
            "  --workers N           dataloader threads\n",
            "  --base-size BASE_SIZE\n",
            "                        base image size\n",
            "  --crop-size CROP_SIZE\n",
            "                        crop image size\n",
            "  --sync-bn SYNC_BN     whether to use sync bn (default: auto)\n",
            "  --freeze-bn FREEZE_BN\n",
            "                        whether to freeze bn parameters (default: False)\n",
            "  --loss-type {ce,focal}\n",
            "                        loss func type (default: ce)\n",
            "  --epochs N            number of epochs to train (default: auto)\n",
            "  --start_epoch N       start epochs (default:0)\n",
            "  --batch-size N        input batch size for training (default: auto)\n",
            "  --test-batch-size N   input batch size for testing (default: auto)\n",
            "  --use-balanced-weights\n",
            "                        whether to use balanced weights (default: False)\n",
            "  --lr LR               learning rate (default: auto)\n",
            "  --lr-scheduler {poly,step,cos}\n",
            "                        lr scheduler mode: (default: poly)\n",
            "  --momentum M          momentum (default: 0.9)\n",
            "  --weight-decay M      w-decay (default: 5e-4)\n",
            "  --nesterov            whether use nesterov (default: False)\n",
            "  --no-cuda             disables CUDA training\n",
            "  --gpu-ids GPU_IDS     use which gpu to train, must be a comma-separated list\n",
            "                        of integers only (default=0)\n",
            "  --seed S              random seed (default: 1)\n",
            "  --resume RESUME       put the path to resuming file if needed\n",
            "  --checkname CHECKNAME\n",
            "                        set the checkpoint name\n",
            "  --ft                  finetuning on a different dataset\n",
            "  --eval-interval EVAL_INTERVAL\n",
            "                        evaluuation interval (default: 1)\n",
            "  --no-val              skip validation during training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "0YKjkApVS6Vg",
        "outputId": "11b53aee-087e-462c-b6b1-498a377e6307"
      },
      "source": [
        "!pip install argparse\n",
        "import os\n",
        "import numpy\n",
        "import argparse"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk60tnzCS9H2",
        "outputId": "d55f1c80-affd-4c71-f1dd-ac64290280c3"
      },
      "source": [
        "from mypath import Path\n",
        "print(Path.db_root_dir('pascal'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VOCdevkit/VOC2012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTZngRe6Vw19"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvCAt8GCTAUJ",
        "outputId": "022bd01e-c627-45ee-de27-732b38e41fac"
      },
      "source": [
        "!python train.py --dataset 'pascal'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(backbone='resnet', base_size=513, batch_size=4, checkname='deeplab-resnet', crop_size=513, cuda=True, dataset='pascal', epochs=50, eval_interval=1, freeze_bn=False, ft=False, gpu_ids=[0], loss_type='ce', lr=0.007, lr_scheduler='poly', momentum=0.9, nesterov=False, no_cuda=False, no_val=False, out_stride=16, resume=None, seed=1, start_epoch=0, sync_bn=False, test_batch_size=4, use_balanced_weights=False, use_sbd=True, weight_decay=0.0005, workers=4)\n",
            "Number of images in train: 1464\n",
            "Number of images in val: 1449\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 303, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 292, in main\n",
            "    trainer = Trainer(args)\n",
            "  File \"train.py\", line 30, in __init__\n",
            "    self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n",
            "  File \"/content/pytorch-deeplab-xception/dataloaders/__init__.py\", line 10, in make_data_loader\n",
            "    sbd_train = sbd.SBDSegmentation(args, split=['train', 'val'])\n",
            "  File \"/content/pytorch-deeplab-xception/dataloaders/datasets/sbd.py\", line 46, in __init__\n",
            "    with open(os.path.join(self._dataset_dir, splt + '.txt'), \"r\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/datasets/benchmark_RELEASE/dataset/train.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7wPJlvLTCv2"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}