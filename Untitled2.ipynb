{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogo96/pytorch-deeplab-xception/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-XYnjXJRT21",
        "outputId": "33e3ca8a-1e76-47fa-b19e-6521cc01fedf"
      },
      "source": [
        "!git clone https://github.com/rogo96/pytorch-deeplab-xception.git"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-deeplab-xception'...\n",
            "remote: Enumerating objects: 348, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 348 (delta 1), reused 0 (delta 0), pack-reused 342\u001b[K\n",
            "Receiving objects: 100% (348/348), 948.60 KiB | 26.35 MiB/s, done.\n",
            "Resolving deltas: 100% (192/192), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3FqQmIpRVGh",
        "outputId": "5a10fa9b-8829-4748-b01b-6015404e7a38"
      },
      "source": [
        "%cd pytorch-deeplab-xception"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch-deeplab-xception/pytorch-deeplab-xception\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xd4_coKRZ0c",
        "outputId": "b241e6f6-67fd-4083-cb9e-7a9652e6f66a"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnv3y447RbQC"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qe10jYmRdMp",
        "outputId": "55257108-5d5b-4d61-c3af-2c628c93e364"
      },
      "source": [
        "!pip install matplotlib pillow tensorboardX tqdm"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkbAp54jRfZq",
        "outputId": "ec88f97f-3905-4c28-da42-5a9a9897a87a"
      },
      "source": [
        "!python train.py -h"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--backbone {resnet,xception,drn,mobilenet}]\n",
            "                [--out-stride OUT_STRIDE] [--dataset {pascal,coco,cityscapes}]\n",
            "                [--use-sbd] [--workers N] [--base-size BASE_SIZE]\n",
            "                [--crop-size CROP_SIZE] [--sync-bn SYNC_BN]\n",
            "                [--freeze-bn FREEZE_BN] [--loss-type {ce,focal}] [--epochs N]\n",
            "                [--start_epoch N] [--batch-size N] [--test-batch-size N]\n",
            "                [--use-balanced-weights] [--lr LR]\n",
            "                [--lr-scheduler {poly,step,cos}] [--momentum M]\n",
            "                [--weight-decay M] [--nesterov] [--no-cuda]\n",
            "                [--gpu-ids GPU_IDS] [--seed S] [--resume RESUME]\n",
            "                [--checkname CHECKNAME] [--ft] [--eval-interval EVAL_INTERVAL]\n",
            "                [--no-val]\n",
            "\n",
            "PyTorch DeeplabV3Plus Training\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --backbone {resnet,xception,drn,mobilenet}\n",
            "                        backbone name (default: resnet)\n",
            "  --out-stride OUT_STRIDE\n",
            "                        network output stride (default: 8)\n",
            "  --dataset {pascal,coco,cityscapes}\n",
            "                        dataset name (default: pascal)\n",
            "  --use-sbd             whether to use SBD dataset (default: True)\n",
            "  --workers N           dataloader threads\n",
            "  --base-size BASE_SIZE\n",
            "                        base image size\n",
            "  --crop-size CROP_SIZE\n",
            "                        crop image size\n",
            "  --sync-bn SYNC_BN     whether to use sync bn (default: auto)\n",
            "  --freeze-bn FREEZE_BN\n",
            "                        whether to freeze bn parameters (default: False)\n",
            "  --loss-type {ce,focal}\n",
            "                        loss func type (default: ce)\n",
            "  --epochs N            number of epochs to train (default: auto)\n",
            "  --start_epoch N       start epochs (default:0)\n",
            "  --batch-size N        input batch size for training (default: auto)\n",
            "  --test-batch-size N   input batch size for testing (default: auto)\n",
            "  --use-balanced-weights\n",
            "                        whether to use balanced weights (default: False)\n",
            "  --lr LR               learning rate (default: auto)\n",
            "  --lr-scheduler {poly,step,cos}\n",
            "                        lr scheduler mode: (default: poly)\n",
            "  --momentum M          momentum (default: 0.9)\n",
            "  --weight-decay M      w-decay (default: 5e-4)\n",
            "  --nesterov            whether use nesterov (default: False)\n",
            "  --no-cuda             disables CUDA training\n",
            "  --gpu-ids GPU_IDS     use which gpu to train, must be a comma-separated list\n",
            "                        of integers only (default=0)\n",
            "  --seed S              random seed (default: 1)\n",
            "  --resume RESUME       put the path to resuming file if needed\n",
            "  --checkname CHECKNAME\n",
            "                        set the checkpoint name\n",
            "  --ft                  finetuning on a different dataset\n",
            "  --eval-interval EVAL_INTERVAL\n",
            "                        evaluuation interval (default: 1)\n",
            "  --no-val              skip validation during training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaInPbriRh0X",
        "outputId": "d50eaef9-dd8a-4941-bdbb-a42d3db29b23"
      },
      "source": [
        "!pip install argparse\n",
        "import os\n",
        "import numpy\n",
        "import argparse"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: argparse in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxopS9FvRsTI",
        "outputId": "c41c93ac-872f-4c31-ae6a-671e29ba97ee"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataloaders  modeling\t  README.md\t train_voc.sh\n",
            "doc\t     mypath.py\t  train_coco.sh  Untitled0.ipynb\n",
            "LICENSE      __pycache__  train.py\t utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d33S1RFRkdU",
        "outputId": "607fd626-d603-4979-c9e3-c1aa6d687b7b"
      },
      "source": [
        "from mypath import Path\n",
        "print(Path.db_root_dir('pascal'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VOCdevkit/VOC2012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDCWUWzkRnb8",
        "outputId": "36ab7da0-7433-459c-9e8f-e28a9128509a"
      },
      "source": [
        "!python3 train.py --backbone {'xception'}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in val: 1449\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 303, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 292, in main\n",
            "    trainer = Trainer(args)\n",
            "  File \"train.py\", line 30, in __init__\n",
            "    self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n",
            "  File \"/content/pytorch-deeplab-xception/pytorch-deeplab-xception/dataloaders/__init__.py\", line 10, in make_data_loader\n",
            "    sbd_train = sbd.SBDSegmentation(args, split=['train', 'val'])\n",
            "  File \"/content/pytorch-deeplab-xception/pytorch-deeplab-xception/dataloaders/datasets/sbd.py\", line 46, in __init__\n",
            "    with open(os.path.join(self._dataset_dir, splt + '.txt'), \"r\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/datasets/benchmark_RELEASE/dataset/train.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AcCGGTmR2oB"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2XkcfW5YByT"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}